cluster issues
- general problem: how to do posix ordering on object boundaries using an object store

- osd states:
   data placement vs liveness:  active, inactive, down, failed
- failure model:
   anything more than that?  "temporarily unavailable" type state (for, say, fsck)?

- replication latency.   flush on replicas?
- what does 'complete' mean on new primary?
  - apparently _need_ to examine objects lists always?  would be nice if we didn't!
- "lazy" flush mode, for (just) doing read/write or write/write sharing?


- deleting objects
 - osd's that rejoin
 - must keep stray replicas clean
 - 

- communications failure model.. is it appropriate?
  - reliable, ordered, buffered and flushed on 'down' boundaries?
  - ordered, unreliable?
- what about large messages?  :(


distribution

- osd imbalance?
- osd readjustment









osd fun
//- generalize rep stuff (op_delete, op_truncate, etc.)

- pull plan items need to be removed when they're obsolete.  or, figure out what's old later.
- osdmap history distribution
- double commit?  what does 'complete' mean on a replica?

- ordering writes.. right now it's a free for all in op thread pool

- "same primary" logic needs to be historical unbroken chain of primary-ship... 
    eg maphistory->same_pg_primary_since(pg, epoch)



- osd states

                up   placing data
 active         y    y 
 inactive       y    n
 down           n    y
 failed         n    n







mirror(2):
choose(1, room, root)       -> [ room1 ]
choose(2, cabinet, _)       -> [ cab3 cab2 ]
choose(1, disk, _)          -> [ somediskincab3or2, someotherdiskincab3or2 ]

mirror(4):
choose(2, room, root)       -> [ room1 room2 ]
vert(_)                     -> [ room1; room2 ]
choose(2, cabinet, _)       -> [ cab11 cab12; cab21 cab22 ]
vert(_)                     -> [ cab11; cab12; cab21; cab22 ]
choose(1, disk, _)          -> [ disk; disk; disk; disk ]
horiz(_)                    -> [ disk disk disk disk ]

two goals:
 - separate replicas into failure domains... "floor" in hierarchy
 - limit replica set to a single domain... "ceiling" in hierarchy

additional tricks:
 - explicitly choose disks from different storage pools

mirror(3)
choose(2, disk, primary)    -> [ d1 d2 ]    // fast scsi (or use more complex chooser as above.)
choose(1, disk, tertiary)   -> [ d1 d2 d3 ] // ide 

results are appended to _, unless _ is used as an input, in which case it is cleared.





R(5, 0, [ s1 s2 s3 s4 ... ])  -> [ d1 d2 d3 d4 ]
= 5 disks

R(3, 2, [ c1 c2 c3 .. ])' -> [ c8; c1; c3 ]
R(3, 0, _)' -> [ d81 d11 d33 ; d82 d14 d31 ; d84 d15 d38 ]
= 9 disks

R(3, 2, cabs)' -> 3 cabs
R(3, 1, _)'    -> 9 shelves
R(1, 0, _)     -> 9 disks



- weighting?
- how to choose from sets (of sets (...))?




R : choose K from set (K<=|set|, draw w/o relacement)
T : choose K from set (K<=|set|, prime thing)
P : choose K from set (prime thing, spillover)
R : choose set from sequence (via hypergeometric, weights)
T : choose set from tree (via hash, node weights+labels)








T(3, 3, _)'   -> [ r1; r2; r3 ]
R(3, 1, _)    -> [ s1 s2 s3; s4 s5 s6; s7 s8 s9 ]
R(1, 0, _)    -> [ d1; d4; d7 ]






s1 = [ 1 2 3 4 5 6 ]
s2 = [ 7 8 9 10 11 12 13 ]
s3 = 
s4 = 

c1 = [ s1 s2 ]
c2 = [ s3 s4 ]
c3 = [ s5 s6 ]
c4 = [ s7 s8 ]

row1 = [ c1 c2 c3 c4 ]
row2 = [ ... ]

room1 = [ row1 row2 ]

choose(1, choose(4, rows))


C(1, room1)   -> row2
C(2, _)       -> [ r2 ; r3 ]
C(1, _)       -> [ C(1, expand(r2)) ; C(1, expand(r3)) ]



C(4, C(1, room1) )




choose 
C(4, expand(rows))





C(3, rows) 









IPDPS

map/reduce refs
12 huston:    diamond
  - early discard    .. distributed filters to reduce data... ultra-parallel grep
13 fischer: parallel prefix coputation.. N records in log N time?

15 riedel:fast01 active disks for large scale data processing
  - nearest neighbor .. sort of a map only, no distributed reduce
  - association rule .. successive passives over map
16 condor - cluster mgmt
17 bulk synchronous



o locality aware scheduling
o fine partitioning -> balanced scheduling
o redundant execution and re-execution



REPLICATION

requirements
- We should support a fast succession of map updates, even when intermediate reorganizations are not allowed to complete before the next starts.
- Reorganizations can be arbitrary, potentially involving a completely disparate set of OSDs in a RG between epochs.  (We will of course seek to minimize movement in practice.)





- interactive hash/unhash interface
- test hashed readdir
- make logstream.flush align itself to stipes

- carefully define/document frozen wrt dir_auth vs hashing





KNOWN BUGS to fix after fast
- fix softlock, stat
- implement truncate() for real
- hard links!


UPCOMING TODOS:
- redo CDir hash_map in terms of const char * in CDentry?
 - or try google's hash library!!


finish HARD LINKS
- reclaim danglers from inode file on discover...
- fix rename



MDS TODO
- fix hashed readdir: should (optionally) do a lock on dir namespace
- fix hard links
  - they mostly work, but they're fragile
- sync clients on stat
  - will need to ditch 10s client metadata caching before this is useful
  - implement truncate
- implement hashed directories
- statfs?
- rewrite journal + recovery
- figure out online failure recovery
- more distributed fh management?
- btree directories (for efficient large directories)
- consistency points/snapshots

OSD TODO
- heartbeat
- collaborative write replication/commit protocol
- collections
- osd failure recovery
- osd cluster expansion

CLIENT TODO
- buffer cache
  - set proper uid/gid 
  - use unused buffer tail allocation before allocating new memory
  - periodic trim_bcache calls
- strong consistency
  - get short-term leases from MDS (for stat etc)
- ditch FUSE for ____



- fix MExportAck and others to use dir+dentry, not inode
  (otherwise this all breaks with hard links.. altho it probably needs reworking already?)


why qsync could be wrong (for very strict POSIX) : varying mds -> client message transit or processing times.
- mds -> 1,2 : qsync
- client1 writes at byte 100
- client1 -> mds : qsync reply (size=100)
- client1 writes at byte 300
- client1 -> client2 (outside channel)
- client2 writes at byte 200
- client2 -> mds : qsync reply (size=200)
-> stat results in size 200, even though at no single point in time was the max size 500.
-> for correct result, need to _stop_ client writers while gathering metadata.


SAGE:

- figure out threading, locking stuff in client

- global sync (to be used by shutdown)
  - flush all dirty data to disk
  - flush logs/journals

- scatter/gather parallel sendrecv (for client file i/o)?
  - use Filer, Cond's
- prefetch?

- sync clients on stat
  - truncate

- readdir
 - set up waiters for pending xlocks

fully document export process
 - including the whole warning business.. wtf is that about again?

- string table?

- hard links
 - fix MExportAck and others to use dir+dentry, not inode
   (otherwise this all breaks with hard links.. altho it probably needs reworking already!)

- do real permission checks?

- journal entries, recovery system


CLIENT TODO

- statfs
- readdir content only optionally includes valid inode info
- pay attention to file_caps on read, write
  - block on lacking caps



FILE STUFF (old)

- send all file writers to auth
  - migrate open file ppl w/ export
  - simplify replica softlock craziness!

- locks versus import.. big mess!
  - consider active reader+writer on auth at time of export.  how to relax?
  - relaxation in general is tricky..
  - assimilating auth state on importer also tricky.  gather_set weirdness.

- half-assed async for file writers
 - auth needs to know about replicas with writers...
   - opens go to auth
   - auth has set of replica_writers
   - on close, replica tells auth
- replace replica_writers open/close bit will full-blown soft_start/soft_finish hooks?
- need to sync or qsync clients!

- import port soft writer on dir mtime/size...

- recall messages?
- lazy flag?  make a table!
- state diagram for master?  _eval() functions?


- think about softlock.mode versus shutdown
- qsync

- freeze interaction.....  test!
  - freeze state diagram?




ISSUES


- discover
 - soft: authority selectively repicates, or sets a 'forward' flag in reply
 - hard: authority always replicates (eg. discover for export)
 - forward flag (see soft)
 - error flag   (if file not found, etc.)
 - [what was i talking about?] make sure waiters are properly triggered, either upon dir_rep update, or (empty!) discover reply



CLEANUP
- waiters after export... fix will_fail, will_delegate nonsense
 - should a subset of these waiters be triggered immediately after
   export, since discover-based contexts will just be forwarded to the
   new auth?


DOCUMENT
- cache, distributed cache structure and invariants
- export process
- hash/unhash process


TEST
- hashing
 - test hash/unhash operation
 - hash+export: encode list of replicated dir inodes so they can be discovered before import is procesed.
 - test nauthitems (wrt hashing?)


IMPLEMENT

- truncate

- hash + unhash!

- dir sync
 - stat of a dir should return dir mtime?
 - readdir of hashed dir


- smarter balancing
  - popularity calculation and management is inconsistent/wrong.
  - does it work?

- instrumentation!
- dump active config in run output somewhere

- anchors
- hard links

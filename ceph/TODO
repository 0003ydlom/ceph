

== FAST rados paper


cluster map
- map distribution

data distribution
 placement groups

replication operation

failure detection
 osd monitor
 up/down/in/out

pg logging
 top, bottom, trimming, etc.
 caller stamps -> idempotent operations

pg recovery
 wrt logs, objects
 wrt active ops


ebofs
 on disk layout
 data safety
 storage interface

 

-- rados applications 
- files
- b-link trees
- distributed hash table
- fifo queues




== rados client nodes

why do we want client op ordering?
- simpler logic in objectcacher
- can pipeline lock + write + unlock, etc.
  - (at least, wrt to single objects..)
- all complexity is in Objecter
  - barrier: waitfor outstanding acks whenever primary osd shifts.

why don't we need it?
- can make compound write+unlock...
- don't actually need ordering for concurrent client ops..

---> we want it.


* ObjectCacher currently assumes reads+acks+commits over an _object_ are ordered.
 -> they are.

- primary changes by pg
- actual discontinuity is over disks
- but the ordering is over objects .. not pgs (bc of missing objects, recovery, etc.)

Objecter:
- should order acks over objects, because we want to order the updates (see below)

- on map update and primary change,
 - resubmit to new primary.

- only accept acks from current primary.
- only accept commits from current primary.
- need pg map
  - to detect primary changes,
  - pg crashes




== todo

- how to get usage feedback to monitor?


messenger
- lookup upcall,
- distributed namer (eg send to MSG_ADDR_MON_ANY)
- failure reporting
- share same tcp socket for sender and receiver?
- close idle connections?
- osds: forget idle client addrs

osd/rados
- mark residual pgs obsolete
- deal with divergent disconnected primaries
- rdlocks
- pg_bit changes
- be more careful about how incrementals are shared
- use pg->info.same_role_since wrt replication ops.
- report crashed pgs?

osdmonitor
- osdmonitor needs to monitor some osds...
- osdmon needs to send map to failure reporter
- monitor pgs
- watch osd utilization; adjust overload in cluster map

objecter

objectcacher
- ocacher flushing
- ocacher caps transitions vs locks
- test read locks


reliability
- heartbeat vs ping
- how to choose peer sets
- osdmonitor, filter

ebofs
- allow btree sets instead of maps
- verify LRU behavior sensible: writes go to mid, not top!
- fix NEAR_LAST_FWD   (?)
- combine inodes and/or cnodes into same blocks
- delay allocation
  - or actually, reallocate if dirty is cancelable
- journaling?  in NVRAM?
- clone()



bugs/stability
- fakestore crapping out.. missing timer events?
- figure out weird 40ms latency with double log entries


general
- timer needs cancel sets, schedulers need to cancel outstanding events on shutdown
- gzip in messenger?


remaining hard problems
- how to cope with file size changes and read/write sharing
- mds failure recovery (of course)


crush
- more efficient failure when all/too many osds are down

mds
- only share osdmap updates with clients holding capabilities
- statlite
- stat single writer
- truncate()
- chdir (directory opens!)
- delayed replica caps release... we need to set a timer event? (and cancel it when appropriate?)
- review caps logic versus singular
- finish hard links!
 - reclaim danglers from inode file on discover...
 - fix rename wrt hard links
- interactive hash/unhash interface
- test hashed readdir
- make logstream.flush align itself to stripes

- carefully define/document frozen wrt dir_auth vs hashing

client
- lazyio_*
- flush objectcacher
- atomic sync writes
- flesh out posix layer
- statlite
/- readdir + stat
- readdirplus
- lazy_*  (after object cache)

- test client caps with meta exports
- some heuristic behavior to consolidate caps to inode auth
- client will re-tx anything it needed to say upon rx of new mds notification (?)

- readv+writev, readx+writex
  - serialized!





cluster issues
- communications failure model.. is it appropriate?
  - reliable, ordered, buffered and flushed on 'down' boundaries?
  - ordered, unreliable?
- what about large messages?  :(




REPLICATION

requirements
- We should support a fast succession of map updates, even when intermediate reorganizations are not allowed to complete before the next starts.
- Reorganizations can be arbitrary, potentially involving a completely disparate set of OSDs in a RG between epochs.  (We will of course seek to minimize movement in practice.)



MDS TODO
- fix hashed readdir: should (optionally) do a lock on dir namespace?
- fix hard links
  - they mostly work, but they're fragile
- sync clients on stat
  - will need to ditch 10s client metadata caching before this is useful
  - implement truncate
- implement hashed directories
- statfs?
- rewrite journal + recovery
- figure out online failure recovery
- more distributed fh management?
- btree directories (for efficient large directories)
- consistency points/snapshots

- fix MExportAck and others to use dir+dentry, not inode
  (otherwise this all breaks with hard links.. altho it probably needs reworking already?)





why qsync could be wrong (for very strict POSIX) : varying mds -> client message transit or processing times.
- mds -> 1,2 : qsync
- client1 writes at byte 100
- client1 -> mds : qsync reply (size=100)
- client1 writes at byte 300
- client1 -> client2 (outside channel)
- client2 writes at byte 200
- client2 -> mds : qsync reply (size=200)
-> stat results in size 200, even though at no single point in time was the max size 500.
-> for correct result, need to _stop_ client writers while gathering metadata.


SAGE:

- global sync (to be used by shutdown)
  - flush all dirty data to disk
  - flush logs/journals

- readdir
 - set up waiters for pending xlocks

- string table?

- hard links
 - fix MExportAck and others to use dir+dentry, not inode
   (otherwise this all breaks with hard links.. altho it probably needs reworking already!)

- do real permission checks?



CLIENT TODO

- statfs
- readdir content only optionally includes valid inode info





ISSUES


- discover
 - soft: authority selectively repicates, or sets a 'forward' flag in reply
 - hard: authority always replicates (eg. discover for export)
 - forward flag (see soft)
 - error flag   (if file not found, etc.)
 - [what was i talking about?] make sure waiters are properly triggered, either upon dir_rep update, or (empty!) discover reply



CLEANUP
- waiters after export... fix will_fail, will_delegate nonsense
 - should a subset of these waiters be triggered immediately after
   export, since discover-based contexts will just be forwarded to the
   new auth?


DOCUMENT
- cache, distributed cache structure and invariants
- export process
- hash/unhash process


TEST
- hashing
 - test hash/unhash operation
 - hash+export: encode list of replicated dir inodes so they can be discovered before import is procesed.
 - test nauthitems (wrt hashing?)


IMPLEMENT

- smarter balancing
  - popularity calculation and management is inconsistent/wrong.
  - does it work?

- instrumentation!
- dump active config in run output somewhere



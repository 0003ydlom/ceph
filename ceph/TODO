

make graphs from dat runs:

 /makedirs
 /ossh.lib
 /ossh.include

 makedirs tput vs lat

 openshared
 writefiles





llnl direct deposit  fax 925 424 2663


mpiexec -l -n 28 ./tcpsyn --mkfs --ebofs --syn until 100 --syn writefile 1000 1048576 --nummds 1 --numclient 112 --numosd 7 --kill_after 120 --osd_object_layout hashino --osd_pg_layout hash --osd_pg_bits 12 --file_layout_num_rep 1 --debug_after 110 --debug_osd 15 --debug_filer 15 --debug 5 --log_name osd/striping.cperbig/cper=16,osd_object_layout=hashino,osd_pg_layout=hash,writefile_size=1048576 > log/osd/striping.cperbig/cper=16,osd_object_layout=hashino,osd_pg_layout=hash,writefile_size=1048576/o && touch log/osd/striping.cperbig/cper=16,osd_object_layout=hashino,osd_pg_layout=hash,writefile_size=1048576/.done &

mpiexec -l -n 28 ./tcpsyn --mkfs --ebofs --syn until 100 --syn writefile 1000 1048576 --nummds 1 --numclient 896 --numosd 7 --kill_after 120 --osd_object_layout hashino --osd_pg_layout crush --osd_pg_bits 12 --file_layout_num_rep 1 --debug_after 110 --debug_osd 15 --debug_filer 15 --debug 5 --log_name osd/striping.cperbig/cper=128,osd_object_layout=hashino,osd_pg_layout=crush,writefile_size=1048576 > log/osd/striping.cperbig/cper=128,osd_object_layout=hashino,osd_pg_layout=crush,writefile_size=1048576/o && touch log/osd/striping.cperbig/cper=128,osd_object_layout=hashino,osd_pg_layout=crush,writefile_size=1048576/.done &

mpiexec -l -n 28 ./tcpsyn --mkfs --ebofs --syn until 100 --syn writefile 1000 1048576 --nummds 1 --numclient 448 --numosd 7 --kill_after 120 --osd_object_layout hashino --osd_pg_layout hash --osd_pg_bits 12 --file_layout_num_rep 1 --debug_after 110 --debug_osd 15 --debug_filer 15 --debug 5 --log_name osd/striping.cperbig/cper=64,osd_object_layout=hashino,osd_pg_layout=hash,writefile_size=1048576 > log/osd/striping.cperbig/cper=64,osd_object_layout=hashino,osd_pg_layout=hash,writefile_size=1048576/o && touch log/osd/striping.cperbig/cper=64,osd_object_layout=hashino,osd_pg_layout=hash,writefile_size=1048576/.done &




541 488 0496  warren


TONIGHT TODO

/make comb calc latency

/finish openshared run

vary cper on makedirs mds=96, make a nice tput/lat curve
do big makedirs run w/ smaller set of mds sizes

fill out ossh.lib  (read to go, just exclude cper 50 .. or adjust bc of above)


FINAL data sets...

makedirs
  n1 good.
  n3 is skewed down.. not clear why?
  big has low cper values!  doh.       **rerun if possible?**

makedirs.tput






MAR 1

makedirs
 final --> 12  
 fixed lb -> m2

	 -> do it again with cper 50,100 , max 2,3   .. ready!   ->  all about the same.
plot "log/alcdat/makedirs.n1/c" u 1:2 t "cper=100,mds_bal_max=2", "log/alcdat/makedirs.n1/c" u 1:3 t "cper=100,mds_bal_max=3", "log/alcdat/makedirs.n1/c" u 1:4 t "cper=50,mds_bal_max=2", "log/alcdat/makedirs.n1/c" u 1:5 t "cper=50,mds_bal_max=3";

	/**-> bal_max=1, cper=100   (n2)
plot "log/alcdat/makedirs.n2/c" u 1:2 t "cper=100,mds_bal_max=1";
   .. same same

	**-> bal_max=2  cper=15,25  (n3)  ready   Q/

makedirs.big

	**-> nbig1 .. flop!  overlay no worky
	**-> nbig4 ..                             Q/

	
makedirs.tput
 finalish -> 1

	**-> ready.. run (last!) to fill in gaps ..   (2)   Q

  ** running subset of points tho, as (2)!  be careful merging results, not all data points for all runs!!
	

ossh.lib
 cper 50 looks good when nummds=48..

  f14 is ok...
    repeat w/ range of cper (besides just 50)

	-> run with cper range              .. ready
plot "log/alcdat/ossh.lib.n1/c" u 1:2 t "cper=100", "log/alcdat/ossh.lib.n1/c" u 1:3 t "cper=25", "log/alcdat/ossh.lib.n1/c" u 1:4 t "cper=50";
  .. only 25 is good at scale!

	**-> cper=10,16     (n2)  ready                 Q


ossh.lib.big

	**-> ready



ossh.include
 max 2 @ 80, cper 75

 best so far is d12.  
 no, f13 is better.

d9 80 was good too?   cper=50 : log/alcdat/ossh.include.d9/cper=50,nummds=128/o   ... srun --wait=120 --exclude=jobs/ltest.ignore -l -t 7 -N 385 -p ltest ./tcpsyn --mkfs --ebofs --syn until 300 --nummds 128 --numclient 6400 --numosd 128 --kill_after 400 --mds_bal_rep 1700 --mds_bal_interval 45 --mds_bal_max 2 --mds_decay_halflife 30 --mds_bal_hash_rd 100000 --tcp_skip_rank0 --mds_shutdown_check 60 --syn only 0 --syn trace traces/openssh/untar.include 1 --syn sleep 30 --syn trace traces/openssh/make.include 1000 --log_name alcdat/ossh.include.d9/cper=50,nummds=128 > log/alcdat/ossh.include.d9/cper=50,nummds=128/o && touch log/alcdat/ossh.include.d9/cper=50,nummds=128/.done &

	-> run with cper range   ... ready  (n1 good!)
plot "log/alcdat/ossh.include.n1/c" u 1:2 t "cper=100", "log/alcdat/ossh.include.n1/c" u 1:3 t "cper=25", "log/alcdat/ossh.include.n1/c" u 1:4 t "cper=50";


	**-> extend w/ cper 15,20  (n2)   ..only if time..


ossh.include.big

	**-> nbig2 ready



makefiles
 cper + nummds   ... ok, 4   ... go back and fill in data points if time!
 150 > 100. check 200 if time


openshared
 f3 .. has various cper



mdtest




striping
 light vs saturated vs supersaturated?
 stripe size



gotchas
 - watch out for cper too large.. bogs down mds0, fucks load balancer



opensshinclude
 choose osdfac  -> 1
 test overlay_clients  .. scale nummds
 or condense clients into fewer nodes?
 fix up ossh.include




- aged object stores on googoo

- confirm block dev versus big file

- ldceph + mdtest

- stability
 - ebofs table.remove() thing
 - fakestore crapping out.. missing timer events?
mpiexec -l -n 30 ./tcpsyn --mkfs --ebofs --syn until 100 --syn writefile 1000 65536 --nummds 1 --numclient 100 --numosd 6 --kill_after 300 --file_layout_num_rep 1 --debug_after 110 --debug_osd 15 --debug_filer 15 --debug 5 --mds_shutdown_check 60 --log_name osd/write_sizes.sdb2.ebo.file2/fs=ebofs,writefile_size=65536

2: tcpsyn: mds/MDCache.cc:2388: void MDCache::handle_cache_expire(MCacheExpire*): Assertion `in->state_test((1<<6))' failed.
2: tcpsyn: mds/MDCache.cc:2388: void MDCache::handle_cache_expire(MCacheExpire*): Assertion `in->state_test((1<<6))' failed.
2: mds1 on tcprank 3 googoo-27.2013
2: mds1 on tcprank 2 googoo-27.1693

1: tcpsyn: mds/MDCache.cc:2382: void MDCache::handle_cache_expire(MCacheExpire*): Assertion `in' failed.
0 on tcprank 24 googoo-17.21123



 - tcpmessenger inq count


- mds
 - vary log stripe size, count  (on ebofs and fakestore)
  ?  4k for ebofs, 64k for fakestore
  ?  scount=4... or 2?
     -> striping mostly useless

- makedirs vs ebo/fake. 
  - streaming small writes (mds log)
     -> ebofs needs 200 clients per MDS to get close to fakestore (compensate for latency?)

- quick retest of crush vs linear


- scaling (scale mds+osd+clients together)
 - metadata
  - makedirs
**     100 c per mds is good on googoo ... testing on alc as mds_log.1
     alc: 4 osd, 200 client per mds   (osd/mds_log.1 .. makedirs)

  - creates in same dir
       --syn makefiles 10000 1000 0 
  - repeat creat+stat+unlink 
  - creates in private dir            ??? easy?
  - repeat creat+stat+unlink          ??? easy?
       --syn makefiles 10000 1000 1

  - zillion opens of the same file
       --syn only 0 --syn createshared 10 --syn openshared 10 1000

  - local compile
       openssh again?
  - shared compile (/lib, /include)
       need something with shared files.. so not a linux kernel :(

* get rid of randomsleep?


 - data scaling .. aggregate tput
  - scale_wr - writes to local files
  - strided write to shared file     ??? meaningless?  (later!)
  - strided write with O_LAZY        ???                later!

 - tput per client
  - local file
  - strided to shared file
  - strided w/ O_LAZY

 - crush vs linear
  - at a large scale!


  



OSDI

- tcp recv throttling

- fix object ov/nv thing?  (tcpmessenger locking bug?)

- tune ebofs

- vary osd_maxthreads, [ ebofs, fakestore ], write_size 
  -> medium, large writes: ebofs 10% faster
  -> small writes: fake 20% faster
- obfs?

- osd write tests
 - ebofs vs fakestore:
      plot "log/osd/write_sizes.swap1.block/c" u 1:2 t "fs=ebofs", "log/osd/write_sizes.sdb2.ext3.fake/c" u 1:2 t "fs=fakestore.sdb2", "log/osd/write_sizes.sdb2.ext3.fake2/c" u 1:2 t "fs=fakestore.sdb2.again", "log/osd/write_sizes.sdb2.ebo/c" u 1:2 t "fs=ebofs.again"
 - get obfs working?

- client buffer cache!

- ld_preload?


- crush creeping performance degradation due to dead nodes    -- richard g.



need post osdi:

mds
 statlite
 stat single writer

client
 flesh out posix layer
 statlite
 readdir + stat
 readdirplus
 lazy_*

osd
 new rados mech



client
- test client caps with meta exports
- some heuristic behavior to consolidate caps to inode auth
- client will re-tx anything it needed to say upon rx of new mds notification (?)

- readv+writev, readx+writex
  - serialized!
- O_LAZY 
  - synchronize_*
- statlite

- LD_PRELOAD


filer
- (optional) serial behavior when read spans objects
  - (altho we still can't get atomicity)
  - ...do a short return in those cases? ..maybe a 'bool atomic' flag..

mds
- delayed replica caps release... we need to set a timer event!  (and cancel it when appropriate)
- implement/test truncate()
- chdir
  - client handles for directories!

ebofs
- fix NEAR_LAST_FWD 
- combine inodes into same blocks?
- delay allocation
  - actually, reallocate if dirty is cancelable
- journaling
- clone(), and/or snapshots

osd
- new ardos scheme
  - directory!
- osdmap history distribution

- handle down osds
- pg_bit changes

- 'dirty' log on primary?
  - fast recovery from degraded mode

- watch osd utilization; adjust cluster map


lazy posix
- softstat, etc.



cluster issues
- general problem: how to do posix ordering on object boundaries using an object store

- osd states:
   data placement vs liveness:  active, inactive, down, failed
- failure model:
   anything more than that?  "temporarily unavailable" type state (for, say, fsck)?

- replication latency.   flush on replicas?
- what does 'complete' mean on new primary?
  - apparently _need_ to examine objects lists always?  would be nice if we didn't!
- "lazy" flush mode, for (just) doing read/write or write/write sharing?


- deleting objects
 - osd's that rejoin
 - must keep stray replicas clean

- communications failure model.. is it appropriate?
  - reliable, ordered, buffered and flushed on 'down' boundaries?
  - ordered, unreliable?
- what about large messages?  :(




REPLICATION

requirements
- We should support a fast succession of map updates, even when intermediate reorganizations are not allowed to complete before the next starts.
- Reorganizations can be arbitrary, potentially involving a completely disparate set of OSDs in a RG between epochs.  (We will of course seek to minimize movement in practice.)



- interactive hash/unhash interface
- test hashed readdir
- make logstream.flush align itself to stipes

- carefully define/document frozen wrt dir_auth vs hashing





KNOWN MDS BUGS to fix after fast
- posix extensions
 - softstat
- implement truncate() for real
- finish hard links!
 - reclaim danglers from inode file on discover...
 - fix rename wrt hard links



MDS TODO
- fix hashed readdir: should (optionally) do a lock on dir namespace
- fix hard links
  - they mostly work, but they're fragile
- sync clients on stat
  - will need to ditch 10s client metadata caching before this is useful
  - implement truncate
- implement hashed directories
- statfs?
- rewrite journal + recovery
- figure out online failure recovery
- more distributed fh management?
- btree directories (for efficient large directories)
- consistency points/snapshots

OSD TODO
- heartbeat
- collaborative write replication/commit protocol
- collections
- osd failure recovery
- osd cluster expansion

CLIENT TODO
- buffer cache
  - set proper uid/gid 
  - use unused buffer tail allocation before allocating new memory
  - periodic trim_bcache calls
- strong consistency
  - get short-term leases from MDS (for stat etc)
- ditch FUSE for ____



- fix MExportAck and others to use dir+dentry, not inode
  (otherwise this all breaks with hard links.. altho it probably needs reworking already?)


why qsync could be wrong (for very strict POSIX) : varying mds -> client message transit or processing times.
- mds -> 1,2 : qsync
- client1 writes at byte 100
- client1 -> mds : qsync reply (size=100)
- client1 writes at byte 300
- client1 -> client2 (outside channel)
- client2 writes at byte 200
- client2 -> mds : qsync reply (size=200)
-> stat results in size 200, even though at no single point in time was the max size 500.
-> for correct result, need to _stop_ client writers while gathering metadata.


SAGE:

- figure out threading, locking stuff in client

- global sync (to be used by shutdown)
  - flush all dirty data to disk
  - flush logs/journals

- scatter/gather parallel sendrecv (for client file i/o)?
  - use Filer, Cond's
- prefetch?

- sync clients on stat
  - truncate

- readdir
 - set up waiters for pending xlocks

fully document export process
 - including the whole warning business.. wtf is that about again?

- string table?

- hard links
 - fix MExportAck and others to use dir+dentry, not inode
   (otherwise this all breaks with hard links.. altho it probably needs reworking already!)

- do real permission checks?

- journal entries, recovery system


CLIENT TODO

- statfs
- readdir content only optionally includes valid inode info
- pay attention to file_caps on read, write
  - block on lacking caps



FILE STUFF (old)

- send all file writers to auth
  - migrate open file ppl w/ export
  - simplify replica softlock craziness!

- locks versus import.. big mess!
  - consider active reader+writer on auth at time of export.  how to relax?
  - relaxation in general is tricky..
  - assimilating auth state on importer also tricky.  gather_set weirdness.

- half-assed async for file writers
 - auth needs to know about replicas with writers...
   - opens go to auth
   - auth has set of replica_writers
   - on close, replica tells auth
- replace replica_writers open/close bit will full-blown soft_start/soft_finish hooks?
- need to sync or qsync clients!

- import port soft writer on dir mtime/size...

- recall messages?
- lazy flag?  make a table!
- state diagram for master?  _eval() functions?


- think about softlock.mode versus shutdown
- qsync

- freeze interaction.....  test!
  - freeze state diagram?




ISSUES


- discover
 - soft: authority selectively repicates, or sets a 'forward' flag in reply
 - hard: authority always replicates (eg. discover for export)
 - forward flag (see soft)
 - error flag   (if file not found, etc.)
 - [what was i talking about?] make sure waiters are properly triggered, either upon dir_rep update, or (empty!) discover reply



CLEANUP
- waiters after export... fix will_fail, will_delegate nonsense
 - should a subset of these waiters be triggered immediately after
   export, since discover-based contexts will just be forwarded to the
   new auth?


DOCUMENT
- cache, distributed cache structure and invariants
- export process
- hash/unhash process


TEST
- hashing
 - test hash/unhash operation
 - hash+export: encode list of replicated dir inodes so they can be discovered before import is procesed.
 - test nauthitems (wrt hashing?)


IMPLEMENT

- truncate

- hash + unhash!

- dir sync
 - stat of a dir should return dir mtime?
 - readdir of hashed dir


- smarter balancing
  - popularity calculation and management is inconsistent/wrong.
  - does it work?

- instrumentation!
- dump active config in run output somewhere

- anchors
- hard links

